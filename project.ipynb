{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SN7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import rasterio\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from glob import glob\n",
    "import geopandas as gpd\n",
    "from rasterio.features import rasterize\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import albumentations as A\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per calcolare media e deviazione standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(image_paths):\n",
    "    means = []  \n",
    "    stds = []  \n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)  # Carica l'immagine inclusi tutti i canali\n",
    "        #img_rgb = img[:, :, :3]  # Prendo i primi tre canali (RGB)\n",
    "        #permute mi serve perchè img la leggo con opencv che mi da HxWxC e pytorch vuole CxHxW\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)  # Converti in tensor e permuta le dimensioni a (Canali, Altezza, Larghezza)\n",
    "\n",
    "        means.append(img_tensor.mean(dim=(1, 2)))  # Calcola e aggiungi la media per ogni canale (RGB) alla lista delle medie (1=h, 2=w)\n",
    "        stds.append(img_tensor.std(dim=(1, 2)))    # Calcola e aggiungi la deviazione standard per ogni canale (RGB) alla lista delle deviazioni standard\n",
    "    \n",
    "    mean = torch.stack(means).mean(dim=0)  # Combina tutte le medie delle immagini e calcola la media finale per ogni canale\n",
    "    std = torch.stack(stds).mean(dim=0)    # Combina tutte le deviazioni standard delle immagini e calcola la deviazione standard finale per ogni canale\n",
    "    \n",
    "    return mean.tolist(), std.tolist()  # Converte i tensori risultanti in liste e li restituisce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media dei canali RGBM: [82.15846252441406, 110.30465698242188, 126.20237731933594, 254.79959106445312]\n",
      "Deviazione standard dei canali RGBM: [27.31522560119629, 30.465126037597656, 38.47288513183594, 3.201913833618164]\n"
     ]
    }
   ],
   "source": [
    "# Path alle immagini nella cartella \"training/images\"\n",
    "image_paths = glob('training/images/*.tif')  \n",
    "\n",
    "# Esegui la computazione su GPU se disponibile\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "mean, std = compute_mean_std(image_paths)\n",
    "\n",
    "print(f'Media dei canali RGBM: {mean}')\n",
    "print(f'Deviazione standard dei canali RGBM: {std}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborazione label:\n",
    "La gestione dell'eccezione: ValueError è dovuta alle immagini e label native del dataset, in pratica in alcune immagini satellitari, c'è la presenza di nuvole, oppure rumore di qualche altro tipo. Per gestire questo rumore è stato creato un 4 canale, che effettua una maschera coprente  sulle zone dove c'è rumore/nuvole. Ci sono anche alcune labels apposite per le maschere. In casi eccezzionali l'intera immagine ha la maschera, dove avviene il mascheramento, le labels ordinarie sono prive di dati geojson, quindi se l'intera immagine è mascherata alcune label sono vuote e quindi cioò comporta quell'errore, che vista l'assenza di label, ho deciso di gestire la problematica semplicemente creando una maschera nera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisce una funzione per creare una maschera binaria da geometrie\n",
    "def create_mask(geojson, img_shape, transform):\n",
    "    shapes = [(geom, 1) for geom in geojson.geometry if geom.is_valid and not geom.is_empty]\n",
    "    if not shapes:\n",
    "        raise ValueError('No valid geometry objects found for rasterize')\n",
    "    mask = rasterize(shapes=shapes, out_shape=img_shape, transform=transform, fill=0, dtype=np.uint8)\n",
    "    return mask\n",
    "\n",
    "# Salva la maschera binaria normalizzata per visualizzazione\n",
    "def save_normalized_mask(mask, output_path, crs, transform):\n",
    "    mask_normalized = (mask * 255).astype(np.uint8)\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=mask_normalized.shape[0],\n",
    "        width=mask_normalized.shape[1],\n",
    "        count=1,\n",
    "        dtype=mask_normalized.dtype,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(mask_normalized, 1)\n",
    "\n",
    "def process_dataset(image_dir, label_dir, output_dir):\n",
    "    image_paths = sorted(glob(os.path.join(image_dir, '*.tif')))\n",
    "    label_paths = sorted(glob(os.path.join(label_dir, '*.geojson')))\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    processed_count = 0\n",
    "\n",
    "    for img_path, label_path in zip(image_paths, label_paths):\n",
    "        labels_match = gpd.read_file(label_path)\n",
    "\n",
    "        with rasterio.open(img_path) as src:\n",
    "            img_shape = (src.height, src.width)\n",
    "            transform = src.transform\n",
    "            img_crs = src.crs\n",
    "\n",
    "        try:\n",
    "            mask_labels_match = create_mask(labels_match, img_shape, transform)\n",
    "        except ValueError as e:\n",
    "            print(f\"Empty or invalid label, noise on image: {img_path} due to error: {e}\")\n",
    "            mask_labels_match = np.zeros(img_shape, dtype=np.uint8)  # Crea una maschera nera in caso di errore\n",
    "        \n",
    "        img_name = os.path.basename(img_path)\n",
    "        mask_name = img_name.replace('.tif', '_label_mask.tif')\n",
    "        mask_output_path = os.path.join(output_dir, mask_name)\n",
    "\n",
    "        save_normalized_mask(mask_labels_match, mask_output_path, img_crs, transform)\n",
    "        \n",
    "        processed_count += 1\n",
    "\n",
    "        if processed_count % 100 == 0:\n",
    "            print(f'Processed: {processed_count} masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train = 'training/images_masked'\n",
    "label_dir_train = 'training/labels/labels_match'\n",
    "mask_dir_train = 'training/mask_from_label'\n",
    "\n",
    "image_dir_valid = 'validation/images_masked'\n",
    "label_dir_valid = 'validation/labels/labels_match'\n",
    "mask_dir_valid = 'validation/mask_from_label'\n",
    "\n",
    "image_dir_test = 'test/images_masked'\n",
    "label_dir_test = 'test/labels/labels_match'\n",
    "mask_dir_test = 'test/mask_from_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_dataset(image_dir_train, label_dir_train, mask_dir_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_dataset(image_dir_valid, label_dir_valid, mask_dir_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_dataset(image_dir_test, label_dir_test, mask_dir_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_paths = sorted(glob(os.path.join(image_dir, '*.tif')))  #liste ordinate con i percorsi\n",
    "        self.mask_paths = sorted(glob(os.path.join(mask_dir, '*.tif')))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read().transpose((1, 2, 0))\n",
    "            #image = image[:, :, :3]  # Considera solo i primi 3 canali (RGB)\n",
    "            image = image.astype(np.float32)\n",
    "            image = (image - mean) / std\n",
    "\n",
    "        with rasterio.open(mask_path) as src:\n",
    "            mask = src.read(1).astype(np.float32)\n",
    "            mask[mask == 255.0] = 1.0  # Conversione per maschera binaria\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DoubleConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "      super(DoubleConv, self).__init__()\n",
    "      self.conv = nn.Sequential(\n",
    "          nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "          nn.BatchNorm2d(out_channels),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "          nn.BatchNorm2d(out_channels),\n",
    "          nn.ReLU(inplace=True),\n",
    "      )\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "  def __init__(\n",
    "      self, in_channels=4, out_channels=1, features=[64, 128, 256, 512],\n",
    "  ):\n",
    "    super(UNET, self).__init__()\n",
    "    self.ups = nn.ModuleList()\n",
    "    self.downs = nn.ModuleList()\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    for feature in features:\n",
    "      self.downs.append(DoubleConv(in_channels, feature))\n",
    "      in_channels = feature\n",
    "\n",
    "    for feature in reversed(features):\n",
    "      self.ups.append(\n",
    "          nn.ConvTranspose2d(\n",
    "              feature*2, feature, kernel_size=2, stride=2,\n",
    "          )\n",
    "      )\n",
    "      self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "    self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "  def forward(self, x):\n",
    "    skip_connections = []\n",
    "\n",
    "    for down in self.downs:\n",
    "      x = down(x)\n",
    "      skip_connections.append(x)\n",
    "      x = self.pool(x)\n",
    "\n",
    "    x = self.bottleneck(x)\n",
    "    skip_connections = skip_connections[::-1]\n",
    "\n",
    "    for idx in range(0, len(self.ups), 2):\n",
    "      x = self.ups[idx](x)\n",
    "      skip_connection = skip_connections[idx//2]\n",
    "\n",
    "      if x.shape != skip_connection.shape:\n",
    "        x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "      x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "    return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler, txtfile):\n",
    "    loop = tqdm(loader)\n",
    "    tot_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.float().to(device=device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data).squeeze(1)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        tot_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = tot_loss / len(loader)\n",
    "    with open(txtfile, \"a\") as f:\n",
    "        f.write(f\"Train Loss: {avg_loss:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni di mantenimento addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"/NN_register/checkpoint.pth.tar\"):\n",
    "  print(\"=> Saving checkpoint\")\n",
    "  torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "  print(\"=> Loading checkpoint\")\n",
    "  model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(loader, model, loss_fn, txtfile, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    total_dice_score = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for num_it, (x, y) in enumerate(loader, start=1):\n",
    "            print(num_it)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x).squeeze(1)\n",
    "            loss = loss_fn(out, y)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.sigmoid(out)\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            num_correct += (preds == y).sum().item()\n",
    "            num_pixels += torch.numel(preds)\n",
    "\n",
    "            dice_score = (2 * (preds * y).sum()) / ((preds + y).sum() + 1e-8)\n",
    "            total_dice_score += dice_score.item()\n",
    "\n",
    "            y_np = y.cpu().numpy().flatten()\n",
    "            preds_np = preds.cpu().numpy().flatten()\n",
    "            total_precision += precision_score(y_np, preds_np, zero_division=1)\n",
    "            total_recall += recall_score(y_np, preds_np, zero_division=1)\n",
    "            total_f1 += f1_score(y_np, preds_np, zero_division=1)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_dice_score = total_dice_score / len(loader)\n",
    "    avg_precision = total_precision / len(loader)\n",
    "    avg_recall = total_recall / len(loader)\n",
    "    avg_f1 = total_f1 / len(loader)\n",
    "    accuracy = num_correct / num_pixels * 100\n",
    "\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Dice score: {avg_dice_score:.4f}\")\n",
    "    print(f\"Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Recall: {avg_recall:.4f}\")\n",
    "    print(f\"F1 Score: {avg_f1:.4f}\")\n",
    "\n",
    "    with open(txtfile, \"a\") as f:\n",
    "        f.write(f\"Validation Loss: {avg_loss:.4f}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "        f.write(f\"Dice score: {avg_dice_score:.4f}\\n\")\n",
    "        f.write(f\"Precision: {avg_precision:.4f}\\n\")\n",
    "        f.write(f\"Recall: {avg_recall:.4f}\\n\")\n",
    "        f.write(f\"F1 Score: {avg_f1:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    model.train()\n",
    "    return avg_loss, accuracy, avg_dice_score, avg_precision, avg_recall, avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_as_imgs(loader, model, folder, device=\"cuda\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    model.eval()\n",
    "    it = 1\n",
    "    for idx, (x, y) in enumerate(tqdm(loader, desc=\"Saving predictions\")):\n",
    "        print(it)\n",
    "        it += 1\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device).unsqueeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "        combined = torch.cat((y, preds), dim=2)\n",
    "        torchvision.utils.save_image(combined, f\"{folder}/comparison_{idx}.tif\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint file not found, starting training from scratch.\n"
     ]
    }
   ],
   "source": [
    "# Usa il percorso relativo alla posizione dello script\n",
    "base_dir = os.getcwd()\n",
    "model_dir = os.path.join(base_dir, \"NN_register\")\n",
    "output_dir = os.path.join(model_dir, \"output\")\n",
    "image_output_dir = os.path.join(model_dir, \"images\")\n",
    "\n",
    "# Assicurati che le directory di output esistano\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(image_output_dir, exist_ok=True)\n",
    "\n",
    "# Definisci i percorsi delle immagini\n",
    "image_dir_train = os.path.join(base_dir, 'training/images_masked')\n",
    "mask_dir_train = os.path.join(base_dir, 'training/mask_from_label')\n",
    "\n",
    "image_dir_valid = os.path.join(base_dir, 'validation/images_masked')\n",
    "mask_dir_valid = os.path.join(base_dir, 'validation/mask_from_label')\n",
    "\n",
    "image_dir_test = os.path.join(base_dir, 'test/images_masked')\n",
    "mask_dir_test = os.path.join(base_dir, 'test/mask_from_label')\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(height=512, width=512),  \n",
    "    A.Normalize(mean=mean, std=std),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=512, width=512),\n",
    "    A.Normalize(mean=mean, std=std),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "train_dataset = SARDataset(image_dir_train, mask_dir_train, transform=transform)\n",
    "val_dataset = SARDataset(image_dir_valid, mask_dir_valid, transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "load_model = True\n",
    "lr = 1e-5\n",
    "step_size = 18\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNET(in_channels=4, out_channels=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=step_size)\n",
    "num_epochs = 20\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "checkpoint_path = os.path.join(model_dir, \"checkpoint.pth.tar\")\n",
    "if load_model and os.path.exists(checkpoint_path):\n",
    "    load_checkpoint(torch.load(checkpoint_path), model)\n",
    "else:\n",
    "    print(\"Checkpoint file not found, starting training from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:48<00:00,  1.30it/s, loss=0.504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "Validation Loss: 0.5445\n",
      "Accuracy: 91.06\n",
      "Dice score: 0.0218\n",
      "Precision: 0.0700\n",
      "Recall: 0.0130\n",
      "F1 Score: 0.0218\n",
      "=> Saving checkpoint\n",
      "New best F1 score: 0.0218\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 31/63 [00:25<00:25,  1.23it/s, loss=0.468]"
     ]
    }
   ],
   "source": [
    "best_f1_score = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    train_fn(train_loader, model, optimizer, criterion, scaler, os.path.join(output_dir, \"output.txt\"))\n",
    "\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    save_checkpoint(checkpoint, os.path.join(model_dir, \"checkpoint.pth.tar\"))\n",
    "\n",
    "    val_loss, val_accuracy, val_dice_score, val_precision, val_recall, val_f1 = eval_fn(val_loader, model, criterion, os.path.join(output_dir, \"output.txt\"), device=device)\n",
    "\n",
    "    if val_f1 > best_f1_score:\n",
    "        best_f1_score = val_f1\n",
    "        save_checkpoint(checkpoint, filename=os.path.join(model_dir, \"best_model.pth.tar\"))\n",
    "        print(f\"New best F1 score: {best_f1_score:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        save_predictions_as_imgs(val_loader, model, image_output_dir, device=device)\n",
    "\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
